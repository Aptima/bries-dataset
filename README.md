# Title
Building Resilient Information Ecosystems: Large LLM-Generated Dataset of Persuasion Attacks

# Authors
Anonymized for Paper Submission 

# Paper
Under Review for NeurIPS 2025 Datasets & Benchmarks Track

---

# Abstract
Organization's communication is essential for public trust, but the rise of generative AI models has introduced significant challenges by generating persuasive content that can form competing narratives with official messages from government and commercial organizations at speed and scale. This has left agencies in a reactive position, often unaware of how these models construct their persuasive strategies, making it more difficult to sustain communication effectiveness. In this paper, we introduce the BRIES dataset, which includes 134,136 attacks generated by GPT-4, Gemma 2, and Llama 3.1 on agency news. These attacks span 23 persuasive techniques from SemEval 2023 Task 3, directed toward 972 press releases from ten agencies. The generated attacks come in two mediums, press release statements and social media posts, covering both long-form and short-form communication strategies. We analyzed the moral resonance of these persuasion attacks  to understand their attack vectors. GPT-4’s attacks mainly focus on Care, with Authority and Loyalty also playing a role. Gemma 2 emphasizes Care and Authority, while Llama 3.1 centers on Loyalty and Care. Analyzing LLM-generated persuasive attacks across models will enable proactive defense, allow to create the reputation armor for organizations, and propel the development of both effective and resilient communications in the information ecosystem.

# Contributions
-	Introduced the BRIES dataset containing 134,136 persuasive attacks generated by GPT-4, Gemma 2, and Llama 3.1 targeting 972 press releases from 10 government and commercial agencies
-	Labeled attacks using 23 persuasive techniques from SemEval 2023 Task 3 to enable detailed strategy analysis
-	Included two communication formats: press release-style statements (long-form) and social media posts (short-form) to capture different persuasive mediums
-	Analyzed the moral foundations behind persuasive attacks, identifying model-specific patterns
    - GPT-4 emphasizes Care, with Authority and Loyalty also present
    - Gemma 2 focuses on Care and Authority
    - Llama 3.1 highlights Loyalty and Care
-	Highlighted the implications of LLM-driven persuasion for proactive organizational defense, reputation resilience, and effective communication design

# Implications
-	**Heightened Communication Challenges**: Generative AI enables the mass production of persuasive content, creating a significant gap between human and machine communicators in terms of influence, speed, and scale.
-	**Moral Resonance as a Strategic Lever**: Identifying how persuasive attacks align with moral themes helps organizations understand which narratives are likely to resonate and influence public perception.
-	**Socio-Emotional-Cognitive Profiling**: Analyzing persuasive content through dimensions such as subjectivity, toxicity, emotion, and intent deepens insight into how LLMs shape audience attitudes and reactions.
-	**Operational Readiness and Countermeasures**: The dataset supports the development of tailored communication strategies that can preempt or mitigate the effects of LLM-generated persuasive attacks.
-	**Building Reputation Armor**: Insights from BRIES help organizations reinforce the credibility and resilience of their messaging in the face of evolving information threats.

---

# Background
In the current digital era, the communication efforts of public and private sector organizations play an essential role in fostering transparency, building public trust, and conveying important updates about policies, services, and initiatives. These communications help make complex organizational functions more understandable and accessible to the public, contributing to more accountable and responsive governance. At the same time, the information environment is rapidly evolving with the emergence of generative artificial intelligence, particularly large language models (LLMs) and multimodal systems such as GPT-4, Gemma 2, and Llama 3.1. These technologies enable the efficient generation of coherent and contextually relevant text, allowing for the creation of content at scale. As these tools become more widely available, they contribute to a broader and more dynamic flow of information across digital platforms.

One of the effects of this development is the growing presence of competing narratives. Generative models can produce content that engages public attention through persuasive framing, simplification of complex topics, or shifts in focus. This can make it more challenging for organizations to ensure that their messages are clearly received and accurately understood. In some cases, key points may be overshadowed or reframed in ways that draw attention away from the original intent of official communications. LLMs are also capable of adopting a range of rhetorical styles that reflect human communication patterns. They may emphasize emotional tone, draw on shared values, or present information in ways that resonate with social and cultural norms. These strategies can influence how people interpret and prioritize information, sometimes amplifying alternative viewpoints or shifting public focus toward particular aspects of an issue.

In this context, organizations must consider how to maintain the clarity, consistency, and relevance of their messaging. Understanding the communication patterns of generative AI systems and the dynamics of competing narratives can support more effective engagement with the public. As the information landscape continues to shift, thoughtful and adaptive communication strategies are necessary to ensure that organizational messages remain visible, meaningful, and trusted.

# Objective
This effort addresses the critical gap in understanding the nuanced persuasive techniques employed by large language models (LLMs) within government communications. While prior studies have acknowledged the general persuasive influence of LLM-generated content on public discourse, they lack detailed, model-specific analyses of how distinct LLMs such as GPT-4, Gemma 2, and Llama 3.1 utilize varied persuasive tactics. Additionally, there is a shortage of systematic investigation into the broad spectrum of persuasive strategies these models deploy in high-impact contexts like public policy and government messaging. To bridge these gaps, we introduce the BRIES dataset, comprising 134,136 persuasive attacks across 23 techniques generated by leading LLMs and linked to 972 news articles from 10 government agencies. By integrating an analysis of moral resonance, our work advances understanding of LLM-driven persuasion and informs the design of more proactive and ethically grounded communication strategies in public governance.

# Agency Press Release
The dataset consists of 972 press release articles gathered from ten U.S. defense and research agencies: Air Force Research Laboratory (AFRL), Army Research Laboratory (ARL), Defense Advanced Research Projects Agency (DARPA), Defense Innovation Unit (DIU), Department of Defense (DoD), Defense Threat Reduction Agency (DTRA), Intelligence Advanced Research Projects Activity (IARPA), National Geospatial-Intelligence Agency (NGA), Naval Research Laboratory (NRL), and Sandia National Laboratories (SNL). Each agency contributed approximately 100 articles, except IARPA, which had 72 at the time of collection.

Using GPT-4o Mini for labeling, the articles were categorized into multiple domains and topics. Across agencies, Defense was the predominant domain, with percentages ranging from 42% in IARPA to as high as 99% in DoD articles. Other frequently labeled domains included Technology, Research & Development (R&D), International Relations, Government, Intelligence, Geospatial Intelligence, Security, Aerospace, and Engineering, reflecting each agency’s focus area. For instance, AFRL’s articles were mostly labeled as Defense (90%), R&D (51%), and Technology (50%), while SNL focused on R&D (68%), Technology (64%), and Engineering (40%).

At the topic level, articles reflected specialized interests consistent with agency missions. AFRL emphasized Military Technology (12%), Military Operations (8%), and R&D (8%). ARL highlighted Military Technology (21%), Machine Learning (14%), and AI (11%). DARPA focused on Machine Learning (12%), National Security (10%), and Military Technology (8%). DIU’s top topics were Defense Innovation (21%), AI (14%), and Military Technology (13%). The DoD’s content centered on Military Cooperation (11%), Regional Security (9%), and Crisis Management (9%). DTRA concentrated on WMD (12%), Threat Reduction (12%), and Counterterrorism (7%). IARPA’s articles mainly addressed AI (22%), Data Analysis (15%), and Machine Learning (11%). NGA prioritized Geospatial Intelligence (22%), National Security (14%), and Geospatial Analysis (14%). NRL’s key topics were Materials Science (9%), Remote Sensing (8%), and Naval Research (8%). SNL’s articles focused on STEM Education (13%), Materials Science (13%), and Nanotechnology (12%).

Overall, the dataset provides a comprehensive view of agency-specific communication, reflecting broad defense priorities alongside specialized research and technological advancements.

# Persuasive Attack Generation
This dataset used a structured approach for generating persuasive attacks on news articles using LLMs. To prevent misuse, the exact prompt is not disclosed. Instead, a layered design framework is outlined, consisting of five components: Attack Fallacy Description, Persona, Perspective Guideline, Argument Guideline, and Writing Style Guideline. Each component plays a specific role in shaping focused, logical, and impactful critiques.

Three language models were used in the process: GPT-4, Gemma 2 9B Instruct, and Llama 3.1 8B Instruct. For each of 972 news articles from ten agencies, 23 types of persuasive attacks were generated, drawn from SemEval 2023 Task 3. Each attack was crafted in both press release and social media post formats to capture variations in communication length and tone. This resulted in a total of 134,136 persuasive attacks targeting key messages in the news content.
